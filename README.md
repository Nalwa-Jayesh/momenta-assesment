# ğŸ™ï¸ Audio Deepfake Detection

## ğŸ“ Overview
This project implements a deep learning model to detect deepfake audio using Mel Spectrogram features. The model is trained on a dataset containing real and fake audio samples.

## ğŸš€ Implementation Details

### ğŸ¤– Model Selection
A **ResNet-based architecture** was chosen due to its effectiveness in learning feature representations from spectrograms.

### ğŸ›ï¸ Data Preprocessing
- ğŸ“Š **Mel Spectrograms** are extracted from audio files using `torchaudio.transforms.MelSpectrogram`.
- ğŸ”§ **Fixed Size Processing**: Spectrograms are padded or truncated to ensure a uniform input size.
- ğŸš« **Skipping Corrupt Files**: Any unreadable or silent files are automatically skipped to maintain dataset integrity.

### ğŸ‹ï¸â€â™‚ï¸ Training and Evaluation
- ğŸ“Œ The dataset is split into **training (80%)**, **validation (10%)**, and **test (10%)** sets.
- âš¡ A standard training loop with **batch normalization and gradient scaling** is used for efficient training.
- ğŸ“ˆ Performance is evaluated using **Accuracy** and **F1-score**.

## ğŸ“Š Performance Results
After training the model for **10 epochs**, the evaluation results were:
- âœ… **Test Accuracy**: **92.64%**
- ğŸ¯ **F1-Score**: **92.29%**

## ğŸ” Strengths and Weaknesses
### âœ… Strengths:
- The **ResNet model generalizes well** to the dataset.
- Effective use of **spectrogram-based feature extraction**.
- Handles **silent and corrupt files gracefully**.

### âŒ Weaknesses:
- Might struggle with **real-world noisy audio conditions**.
- Requires **computational resources** for training.

## ğŸ”® Future Improvements
- ğŸ§ª **Experiment with different architectures** like CNN+LSTM.
- ğŸµ **Apply data augmentation** techniques for better generalization.
- ğŸ™ï¸ **Investigate alternative preprocessing techniques** like MFCCs.

## âš™ï¸ Setup Instructions
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Ensure the dataset is available and formatted correctly.
3. Run `main.ipynb` to **train and evaluate** the model.

## ğŸ“¦ Dependencies
- ğŸ— **PyTorch**
- ğŸ§ **Torchaudio**
- ğŸ”¢ **NumPy**
- ğŸ“Š **Pandas**
- ğŸ“ˆ **Matplotlib**

## ğŸ”„ Reproducibility
To reproduce the results:
1. Follow the **setup instructions**.
2. The instructions for data set is in the first few cells of the notebook.
3. Run the **training script** in `momenta_task.ipynb`.
